{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "## Twitter Sentiment Analysis\n",
    "\n",
    "Twitter Sentiment Analysis using NLP is a project that leverages Natural Language Processing (NLP) techniques to analyze and categorize the sentiment expressed in tweets as positive, negative, or neutral.\n",
    "\n",
    "It aims to understand public opinion or sentiment on specific topics, events, or brands by analyzing tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import joblib\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download necessary NLTK data\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the datasets\n",
    "\n",
    "train_data = pd.read_csv(\"D:/sentiment_analysis/data/twitter_training.csv\",names=['Serial_number', 'Source', 'Sentiments', 'Text'])\n",
    "\n",
    "valid_data = pd.read_csv(\"D:/sentiment_analysis/data/twitter_validation.csv\",names=['Serial_number', 'Source', 'Sentiments', 'Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data shape: (1000, 4)\n",
      "   Serial_number     Source  Sentiments  \\\n",
      "0           3364   Facebook  Irrelevant   \n",
      "1            352     Amazon     Neutral   \n",
      "2           8312  Microsoft    Negative   \n",
      "3           4371      CS-GO    Negative   \n",
      "4           4433     Google     Neutral   \n",
      "\n",
      "                                                Text  \n",
      "0  I mentioned on Facebook that I was struggling ...  \n",
      "1  BBC News - Amazon boss Jeff Bezos rejects clai...  \n",
      "2  @Microsoft Why do I pay for WORD when it funct...  \n",
      "3  CSGO matchmaking is so full of closet hacking,...  \n",
      "4  Now the President is slapping Americans in the...  \n"
     ]
    }
   ],
   "source": [
    "print(f\"Validation data shape: {valid_data.shape}\")\n",
    "print(valid_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (74682, 4)\n",
      "   Serial_number       Source Sentiments  \\\n",
      "0           2401  Borderlands   Positive   \n",
      "1           2401  Borderlands   Positive   \n",
      "2           2401  Borderlands   Positive   \n",
      "3           2401  Borderlands   Positive   \n",
      "4           2401  Borderlands   Positive   \n",
      "\n",
      "                                                Text  \n",
      "0  im getting on borderlands and i will murder yo...  \n",
      "1  I am coming to the borders and I will kill you...  \n",
      "2  im getting on borderlands and i will kill you ...  \n",
      "3  im coming on borderlands and i will murder you...  \n",
      "4  im getting on borderlands 2 and i will murder ...  \n"
     ]
    }
   ],
   "source": [
    "print(f\"Training data shape: {train_data.shape}\")\n",
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]','',text)\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Serial_number       Source Sentiments  \\\n",
      "0               2401  Borderlands   Positive   \n",
      "1               2401  Borderlands   Positive   \n",
      "2               2401  Borderlands   Positive   \n",
      "3               2401  Borderlands   Positive   \n",
      "4               2401  Borderlands   Positive   \n",
      "...              ...          ...        ...   \n",
      "74677           9200       Nvidia   Positive   \n",
      "74678           9200       Nvidia   Positive   \n",
      "74679           9200       Nvidia   Positive   \n",
      "74680           9200       Nvidia   Positive   \n",
      "74681           9200       Nvidia   Positive   \n",
      "\n",
      "                                                    Text  \\\n",
      "0      im getting on borderlands and i will murder yo...   \n",
      "1      I am coming to the borders and I will kill you...   \n",
      "2      im getting on borderlands and i will kill you ...   \n",
      "3      im coming on borderlands and i will murder you...   \n",
      "4      im getting on borderlands 2 and i will murder ...   \n",
      "...                                                  ...   \n",
      "74677  Just realized that the Windows partition of my...   \n",
      "74678  Just realized that my Mac window partition is ...   \n",
      "74679  Just realized the windows partition of my Mac ...   \n",
      "74680  Just realized between the windows partition of...   \n",
      "74681  Just like the windows partition of my Mac is l...   \n",
      "\n",
      "                                          Processed_text  \n",
      "0                          im getting borderlands murder  \n",
      "1                                    coming borders kill  \n",
      "2                            im getting borderlands kill  \n",
      "3                           im coming borderlands murder  \n",
      "4                          im getting borderlands murder  \n",
      "...                                                  ...  \n",
      "74677  realized windows partition mac like years behi...  \n",
      "74678  realized mac window partition years behind nvi...  \n",
      "74679  realized windows partition mac years behind nv...  \n",
      "74680  realized windows partition mac like years behi...  \n",
      "74681  like windows partition mac like years behind d...  \n",
      "\n",
      "[74682 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "train_data['Processed_text'] = train_data['Text'].apply(preprocess_data)\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Serial_number     Source  Sentiments  \\\n",
      "0           3364   Facebook  Irrelevant   \n",
      "1            352     Amazon     Neutral   \n",
      "2           8312  Microsoft    Negative   \n",
      "3           4371      CS-GO    Negative   \n",
      "4           4433     Google     Neutral   \n",
      "\n",
      "                                                Text  \\\n",
      "0  I mentioned on Facebook that I was struggling ...   \n",
      "1  BBC News - Amazon boss Jeff Bezos rejects clai...   \n",
      "2  @Microsoft Why do I pay for WORD when it funct...   \n",
      "3  CSGO matchmaking is so full of closet hacking,...   \n",
      "4  Now the President is slapping Americans in the...   \n",
      "\n",
      "                                      Processed_text  \n",
      "0  mentioned facebook struggling motivation go ru...  \n",
      "1  bbc news amazon boss jeff bezos rejects claims...  \n",
      "2  microsoft pay word functions poorly samsungus ...  \n",
      "3  csgo matchmaking full closet hacking truly awf...  \n",
      "4  president slapping americans face really commi...  \n"
     ]
    }
   ],
   "source": [
    "valid_data['Processed_text'] = valid_data['Text'].apply(preprocess_data)\n",
    "print(valid_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for source: Borderlands\n",
      "Training model for source: CallOfDutyBlackopsColdWar\n",
      "Training model for source: Amazon\n",
      "Training model for source: Overwatch\n",
      "Training model for source: Xbox(Xseries)\n",
      "Training model for source: NBA2K\n",
      "Training model for source: Dota2\n",
      "Training model for source: PlayStation5(PS5)\n",
      "Training model for source: WorldOfCraft\n",
      "Training model for source: CS-GO\n",
      "Training model for source: Google\n",
      "Training model for source: AssassinsCreed\n",
      "Training model for source: ApexLegends\n",
      "Training model for source: LeagueOfLegends\n",
      "Training model for source: Fortnite\n",
      "Training model for source: Microsoft\n",
      "Training model for source: Hearthstone\n",
      "Training model for source: Battlefield\n",
      "Training model for source: PlayerUnknownsBattlegrounds(PUBG)\n",
      "Training model for source: Verizon\n",
      "Training model for source: HomeDepot\n",
      "Training model for source: FIFA\n",
      "Training model for source: RedDeadRedemption(RDR)\n",
      "Training model for source: CallOfDuty\n",
      "Training model for source: TomClancysRainbowSix\n",
      "Training model for source: Facebook\n",
      "Training model for source: GrandTheftAuto(GTA)\n",
      "Training model for source: MaddenNFL\n",
      "Training model for source: johnson&johnson\n",
      "Training model for source: Cyberpunk2077\n",
      "Training model for source: TomClancysGhostRecon\n",
      "Training model for source: Nvidia\n",
      "Training completed. Models saved in 'models' directory.\n"
     ]
    }
   ],
   "source": [
    "def train_source_model(source_data):\n",
    "    X = source_data['Processed_text']\n",
    "    y = source_data['Sentiments']\n",
    "    \n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "    X = tfidf_vectorizer.fit_transform(X)\n",
    "    \n",
    "    model = LinearSVC()\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    return model, tfidf_vectorizer\n",
    "\n",
    "# Train models for each source\n",
    "sources = train_data['Source'].unique()\n",
    "\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')\n",
    "\n",
    "for source in sources:\n",
    "    print(f\"Training model for source: {source}\")\n",
    "    source_data = train_data[train_data['Source'] == source]\n",
    "    model, vectorizer = train_source_model(source_data)\n",
    "    \n",
    "    # Save the model and vectorizer\n",
    "    joblib.dump(model, f'models/{source}_model.joblib')\n",
    "    joblib.dump(vectorizer, f'models/{source}_vectorizer.joblib')\n",
    "\n",
    "print(\"Training completed. Models saved in 'models' directory.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.99      0.98      0.99       172\n",
      "    Negative       0.98      0.98      0.98       266\n",
      "     Neutral       0.99      0.99      0.99       285\n",
      "    Positive       0.98      0.98      0.98       277\n",
      "\n",
      "    accuracy                           0.99      1000\n",
      "   macro avg       0.99      0.99      0.99      1000\n",
      "weighted avg       0.99      0.99      0.99      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def predict_sentiment(text, source):\n",
    "    model = joblib.load(f'models/{source}_model.joblib')\n",
    "    vectorizer = joblib.load(f'models/{source}_vectorizer.joblib')\n",
    "    processed_text = preprocess_data(text)\n",
    "    vectorized_text = vectorizer.transform([processed_text])\n",
    "    prediction = model.predict(vectorized_text)[0]\n",
    "    return prediction\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_predictions = []\n",
    "for _, row in valid_data.iterrows():\n",
    "    pred = predict_sentiment(row['Text'], row['Source'])\n",
    "    val_predictions.append(pred)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(valid_data['Sentiments'], val_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.986\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(valid_data['Sentiments'], val_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: 'I love playing Borderlands! Can't wait to kill some skags!'\n",
      "Source: Borderlands\n",
      "Predicted sentiment: Positive\n",
      "\n",
      "Text: 'This new graphics card is amazing!'\n",
      "Source: Nvidia\n",
      "Predicted sentiment: Positive\n",
      "\n",
      "Text: 'Facebook's new privacy policy is concerning.'\n",
      "Source: Facebook\n",
      "Predicted sentiment: Neutral\n",
      "\n",
      "Text: 'The latest Windows update broke my computer.'\n",
      "Source: Microsoft\n",
      "Predicted sentiment: Negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_texts = [\n",
    "    (\"I love playing Borderlands! Can't wait to kill some skags!\", \"Borderlands\"),\n",
    "    (\"This new graphics card is amazing!\", \"Nvidia\"),\n",
    "    (\"Facebook's new privacy policy is concerning.\", \"Facebook\"),\n",
    "    (\"The latest Windows update broke my computer.\", \"Microsoft\")\n",
    "]\n",
    "\n",
    "for text, source in sample_texts:\n",
    "    try:\n",
    "        sentiment = predict_sentiment(text, source)\n",
    "        print(f\"Text: '{text}'\")\n",
    "        print(f\"Source: {source}\")\n",
    "        print(f\"Predicted sentiment: {sentiment}\\n\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)\n",
    "        print(f\"Text: '{text}'\")\n",
    "        print(f\"Source: {source}\")\n",
    "        print(\"Predicted sentiment: Unable to predict (model not found)\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
